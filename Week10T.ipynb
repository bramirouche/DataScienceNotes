{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering (Continued)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom-Up Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to clustering is to “grow” clusters from the bottom up. We\n",
    "can do this in the following way:\n",
    "1. Make each input its own cluster of one.\n",
    "2. As long as there are multiple clusters remaining, find the two closest clusters and merge them.\n",
    "\n",
    "At the end, we’ll have one giant cluster containing all the inputs. If we keep track of\n",
    "the merge order, we can re-create any number of clusters by unmerging.\n",
    "- For example, if we want three clusters, we can just undo the last two merges.\n",
    "\n",
    "We’ll use a really simple representation of clusters. Our values will live in *leaf* clusters,\n",
    "which we will represent as `NamedTuples`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "inputs: List[List[float]] = [[-14,-5],[13,13],[20,23],[-19,-11],[-9,-16],[21,27],[-49,15],[26,13],[-46,5],[-34,-1],[11,15],[-49,0],[-22,-16],[19,28],[-12,-8],[-13,-19],[-41,8],[-11,-6],[-25,-9],[-18,-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Union\n",
    "Vector = List[float]\n",
    "\n",
    "class Leaf(NamedTuple):\n",
    "    value: Vector\n",
    "\n",
    "leaf1 = Leaf([10,  20])\n",
    "leaf2 = Leaf([30, -15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use these to grow merged clusters, which we will also represent as `NamedTuples`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Merged(NamedTuple):\n",
    "    children: tuple\n",
    "    order: int\n",
    "\n",
    "merged = Merged((leaf1, leaf2), order=1)\n",
    "\n",
    "Cluster = Union[Leaf, Merged]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll talk about merge order in a bit, but first let’s create a helper function that recursively\n",
    "returns all the values contained in a (possibly merged) cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(cluster: Cluster) -> List[Vector]:\n",
    "    if isinstance(cluster, Leaf):\n",
    "        return [cluster.value]\n",
    "    else:\n",
    "        return [value\n",
    "                for child in cluster.children\n",
    "                for value in get_values(child)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_values(merged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to merge the closest clusters, we need some notion of the distance between\n",
    "clusters.\n",
    "- We’ll use the *minimum* distance between elements of the two clusters, which merges the two clusters that are closest to touching (but will sometimes produce large chain-like clusters that aren’t very tight).\n",
    "- If we wanted tight spherical clusters, we might use the *maximum* distance instead, as it merges the two clusters that fit in the smallest ball.\n",
    "- Both are common choices, as is the *average* distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def cluster_distance(cluster1: Cluster,\n",
    "                     cluster2: Cluster,\n",
    "                     distance_agg: Callable = min) -> float:\n",
    "    \"\"\"\n",
    "    compute all the pairwise distances between cluster1 and cluster2\n",
    "    and apply the aggregation function _distance_agg_ to the resulting list\n",
    "    \"\"\"\n",
    "    return distance_agg([distance.euclidean(v1, v2)\n",
    "                         for v1 in get_values(cluster1)\n",
    "                         for v2 in get_values(cluster2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use the merge order slot to track the order in which we did the merging. Smaller\n",
    "numbers will represent *later* merges. This means when we want to unmerge clusters, we do so from lowest merge order to highest. Since `Leaf` clusters were never merged,\n",
    "we’ll assign them infinity, the highest possible value. And since they don’t have\n",
    "an `.order` property, we’ll create a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_order(cluster: Cluster) -> float:\n",
    "    if isinstance(cluster, Leaf):\n",
    "        return float('inf')  # was never merged\n",
    "    else:\n",
    "        return cluster.order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, since `Leaf` clusters don’t have children, we’ll create and add a helper function\n",
    "for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def get_children(cluster: Cluster):\n",
    "    if isinstance(cluster, Leaf):\n",
    "        raise TypeError(\"Leaf has no children\")\n",
    "    else:\n",
    "        return cluster.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’re ready to create the clustering algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_up_cluster(inputs: List[Vector],\n",
    "                      distance_agg: Callable = min) -> Cluster:\n",
    "    # Start with all leaves\n",
    "    clusters: List[Cluster] = [Leaf(input) for input in inputs]\n",
    "\n",
    "    def pair_distance(pair: Tuple[Cluster, Cluster]) -> float:\n",
    "        return cluster_distance(pair[0], pair[1], distance_agg)\n",
    "\n",
    "    # as long as we have more than one cluster left...\n",
    "    while len(clusters) > 1:\n",
    "        # find the two closest clusters\n",
    "        c1, c2 = min(((cluster1, cluster2)\n",
    "                      for i, cluster1 in enumerate(clusters)\n",
    "                      for cluster2 in clusters[:i]),\n",
    "                      key=pair_distance)\n",
    "\n",
    "        # remove them from the list of clusters\n",
    "        clusters = [c for c in clusters if c != c1 and c != c2]\n",
    "\n",
    "        # merge them, using merge_order = # of clusters left\n",
    "        merged_cluster = Merged((c1, c2), order=len(clusters))\n",
    "\n",
    "        # and add their merge\n",
    "        clusters.append(merged_cluster)\n",
    "\n",
    "    # when there's only one cluster left, return it\n",
    "    return clusters[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its use is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cluster = bottom_up_cluster(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces a clustering that looks as follows:\n",
    "![hierarchy_clusters](hierarchy_clusters.png)\n",
    "\n",
    "The numbers at the top indicate “merge order.” Since we had 20 inputs, it took 19\n",
    "merges to get to this one cluster. The first merge created cluster 18 by combining the\n",
    "leaves [19, 28] and [21, 27]. And the last merge created cluster 0.\n",
    "\n",
    "If you wanted only two clusters, you’d split at the first fork (“0”), one branch moving down and the other moving right, creating one cluster\n",
    "with six points and a second with the rest. For three clusters, you’d continue to the\n",
    "second fork (“1”), which indicates to split that first cluster into the cluster with ([19,\n",
    "28], [21, 27], [20, 23], [26, 13]) and the cluster with ([11, 15], [13, 13]). And so on.\n",
    "\n",
    "Generally, though, we don’t want to be squinting at nasty text representations like\n",
    "this. Instead, let’s write a function that generates any number of clusters by performing\n",
    "the appropriate number of unmerges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clusters(base_cluster: Cluster,\n",
    "                      num_clusters: int) -> List[Cluster]:\n",
    "    # start with a list with just the base cluster\n",
    "    clusters = [base_cluster]\n",
    "\n",
    "    # as long as we don't have enough clusters yet...\n",
    "    while len(clusters) < num_clusters:\n",
    "        # choose the last-merged of our clusters\n",
    "        next_cluster = min(clusters, key=get_merge_order)\n",
    "        # remove it from the list\n",
    "        clusters = [c for c in clusters if c != next_cluster]\n",
    "\n",
    "        # and add its children to the list (i.e., unmerge it)\n",
    "        clusters.extend(get_children(next_cluster)) # extends will unpack the children and add each of them to the list\n",
    "\n",
    "    # once we have enough clusters...\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for example, if we want to generate three clusters, we can just do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_clusters = [get_values(cluster)\n",
    "                  for cluster in generate_clusters(base_cluster, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we can easily plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i, cluster, marker, color in zip([1, 2, 3],\n",
    "                                     three_clusters,\n",
    "                                     ['D','o','*'],\n",
    "                                     ['r','g','b']):\n",
    "    xs, ys = zip(*cluster)  # magic unzipping trick\n",
    "    plt.scatter(xs, ys, color=color, marker=marker)\n",
    "\n",
    "    # put a number at the mean of the cluster\n",
    "    x, y = np.mean(cluster, axis = 0)\n",
    "    plt.plot(x, y, marker='$' + str(i) + '$', color='black')\n",
    "\n",
    "plt.title(\"User Locations -- 3 Bottom-Up Clusters, Min\")\n",
    "plt.xlabel(\"blocks east of city center\")\n",
    "plt.ylabel(\"blocks north of city center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives very different results than *k*-means did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, this is because using `min` in `cluster_distance` tends to\n",
    "give chain-like clusters. If we instead use `max` (which gives tight clusters), it looks the\n",
    "same as the 3-means result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cluster2 = bottom_up_cluster(inputs, max)\n",
    "\n",
    "three_clusters2 = [get_values(cluster)\n",
    "                  for cluster in generate_clusters(base_cluster2, 3)]\n",
    "\n",
    "for i, cluster, marker, color in zip([1, 2, 3],\n",
    "                                     three_clusters2,\n",
    "                                     ['D','o','*'],\n",
    "                                     ['r','g','b']):\n",
    "    xs, ys = zip(*cluster)  # magic unzipping trick\n",
    "    plt.scatter(xs, ys, color=color, marker=marker)\n",
    "\n",
    "    # put a number at the mean of the cluster\n",
    "    x, y = np.mean(cluster, axis = 0)\n",
    "    plt.plot(x, y, marker='$' + str(i) + '$', color='black')\n",
    "\n",
    "plt.title(\"User Locations -- 3 Bottom-Up Clusters, Min\")\n",
    "plt.xlabel(\"blocks east of city center\")\n",
    "plt.ylabel(\"blocks north of city center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The previous `bottom_up_clustering` implementation is relatively\n",
    "simple, but also shockingly inefficient. In particular, it recomputes\n",
    "the distance between each pair of inputs at every step. A more efficient\n",
    "implementation might instead precompute the distances\n",
    "between each pair of inputs and then perform a lookup inside `cluster_distance`. A really efficient implementation would likely also\n",
    "remember the `cluster_distances` from the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://machinelearningmastery.com/clustering-algorithms-with-python/\n",
    "\n",
    "# k-means clustering\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate an artificial dataset\n",
    "# when dealing with real datasets, you probably want to load the data via pandas\n",
    "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
    "\n",
    "print(f\"X = {X}\")\n",
    "\n",
    "# define the model\n",
    "model = KMeans(n_clusters=2)\n",
    "\n",
    "# fit the model\n",
    "model.fit(X)\n",
    "\n",
    "# assign a cluster to each example\n",
    "yhat = model.predict(X)\n",
    "\n",
    "print(f\"yhat = {yhat}\")\n",
    "\n",
    "\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "print(f\"clusters = {clusters}\")\n",
    "\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "    # get row indexes for samples with this cluster\n",
    "    row_ix = where(yhat == cluster)\n",
    "    \n",
    "    print(f\"row_ix = {row_ix}\")\n",
    "    \n",
    "    # create scatter of these samples\n",
    "    plt.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "    \n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about other types of clustering in:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/clustering.html\n",
    "\n",
    "https://machinelearningmastery.com/clustering-algorithms-with-python/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
