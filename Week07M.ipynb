{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (Contineud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Week06R import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular (if somewhat old) dataset is the [SpamAssassin public corpus](https://spamassassin.apache.org/old/publiccorpus/). We’ll look at\n",
    "the files prefixed with 20021010.\n",
    "\n",
    "Here is a script that will download and unpack them to the directory of your choice\n",
    "(or you can do it manually):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO # So we can treat bytes as a file.\n",
    "import requests # To download the files, which\n",
    "import tarfile # are in .tar.bz format.\n",
    "\n",
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
    "         \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\"]\n",
    "\n",
    "# This is where the data will end up,\n",
    "# in /spam, /easy_ham, and /hard_ham subdirectories.\n",
    "# Change this to where you want the data.\n",
    "OUTPUT_DIR = 'spam_data'\n",
    "\n",
    "for filename in FILES:\n",
    "    # Use requests to get the file contents at each URL.\n",
    "    content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
    "    \n",
    "    # Wrap the in-memory bytes so we can use them as a \"file.\"\n",
    "    fin = BytesIO(content)\n",
    "    \n",
    "    # And extract all the files to the specified output dir.\n",
    "    with tarfile.open(fileobj=fin, mode='r:bz2') as tf:\n",
    "        tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data you should have three folders: spam, easy_ham, and\n",
    "hard_ham. Each folder contains many emails, each contained in a single file. To keep\n",
    "things really simple, we’ll just look at the subject lines of each email.\n",
    "\n",
    "How do we identify the subject line? When we look through the files, they all seem to\n",
    "start with “Subject:”. So we’ll look for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re\n",
    "\n",
    "# modify the path to wherever you've put the files\n",
    "path = 'spam_data/*/*'\n",
    "\n",
    "data: List[Message] = []\n",
    "\n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for filename in glob.glob(path):\n",
    "    is_spam = \"ham\" not in filename\n",
    "\n",
    "    # There are some garbage characters in the emails, the errors='ignore'\n",
    "    # skips them instead of raising an exception.\n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                data.append(Message(subject, is_spam))\n",
    "                break  # done with this file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the data into training data and test data, and then we’re ready to\n",
    "build a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same split_data function that we've used earlier\n",
    "import random\n",
    "from typing import TypeVar, Tuple\n",
    "X = TypeVar('X')  # generic type to represent a data point\n",
    "\n",
    "def split_data(data: List[X], prob: float) -> Tuple[List[X], List[X]]:\n",
    "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    data = data[:]                    # Make a shallow copy\n",
    "    random.shuffle(data)              # because shuffle modifies the list.\n",
    "    cut = int(len(data) * prob)       # Use prob to find a cutoff\n",
    "    return data[:cut], data[cut:]     # and split the shuffled list there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0) # For illustrative purposes only, so that you will also get the same answer when you execute the code\n",
    "train_messages, test_messages = split_data(data, 0.75)\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(train_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s generate some predictions and check how our model does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "predictions = [(message, model.predict(message.text))\n",
    "               for message in test_messages]\n",
    "\n",
    "print(\"********************************************************************************\")\n",
    "print(predictions[:5])\n",
    "print(\"********************************************************************************\")\n",
    "\n",
    "\n",
    "# Assume that spam_probability > 0.5 corresponds to spam prediction\n",
    "# and count the combinations of (actual is_spam, predicted is_spam)\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                           for message, spam_probability in predictions)\n",
    "\n",
    "print(f\"confusion matrix = {confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives 86 true positives (spam classified as “spam”), 29 false positives (ham classified\n",
    "as “spam”), 670 true negatives (ham classified as “ham”), and 40 false negatives\n",
    "(spam classified as “ham”). This means our precision is 86 / (86 + 29) = 75%, and our\n",
    "recall is 86 / (86 + 40) = 68%, which are not bad numbers for such a simple model.\n",
    "(Presumably we’d do better if we looked at more than the subject lines.)\n",
    "\n",
    "We can also inspect the model’s innards to see which words are least and most indicative\n",
    "of spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "    # We probably shouldn't call private methods, but it's for a good cause.\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "\n",
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "\n",
    "print(\"spammiest_words\", words[-10:])\n",
    "print(\"hammiest_words\", words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spammiest words include things like *sale*, *mortgage*, *money*, and *rates*, whereas\n",
    "the hammiest words include things like *spambayes*, *users*, *apt*, and *perl*. So that also\n",
    "gives us some intuitive confidence that our model is basically doing the right thing.\n",
    "\n",
    "How could we get better performance? One obvious way would be to get more data\n",
    "to train on. There are a number of ways to improve the model as well. Here are some\n",
    "possibilities that you might try:\n",
    "- Look at the message content, not just the subject line.\n",
    "- Our classifier takes into account every word that appears in the training set, even words that appear only once. Modify the classifier to accept an optional `min_count` threshold and ignore tokens that don’t appear at least that many times.\n",
    "- The tokenizer has no notion of similar words (e.g., *cheap* and *cheapest*). Modify the classifier to take an optional `stemmer` function that converts words to *equivalence classes* of words. Creating a good stemmer function is hard. People frequently use the [Porter stemmer](https://tartarus.org/martin/PorterStemmer/). But for illustrative purposes, here is a really simple stemmer function:\n",
    "```python\n",
    "def drop_final_s(word):\n",
    "    return re.sub(\"s$\", \"\", word)\n",
    "```\n",
    "- Although our features are all of the form “message contains word $w_i$,” there’s no reason why this has to be the case. We could add extra features like “message contains a number”.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes from scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scikit-learn` package contains a few variations of the Naive Bayes model. See the documentations at:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "In particular, its `BernoulliNB` model is considered to be equivalent to what we have implemented. Each feature is assumed to be a binary-valued (Bernoulli, boolean) variable, or will be converted to binary features if given other types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randint(2, size=(10, 10))\n",
    "Y = rng.randint(2, size = 10)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, Y)\n",
    "print(f\"actual    = {Y}\")\n",
    "print(f\"predicted = {clf.predict(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another variant, `GaussianNB`, is capable of classifying the *iris* dataset that we've looked at earlier. Without getting into too much into the statistical and mathematical details, you can think of the `GaussianNB` model as capable of handling input features that are numeric floating point values, while the `BernoulliNB` model is able to handle binary input features (e.g., 0 and 1). Of course, there are also other types of features (e.g., categorical input features) that may require other appropriate Naive Bayes variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://machinelearningmastery.com/get-your-hands-dirty-with-scikit-learn-now/\n",
    "# Gaussian Naive Bayes\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
